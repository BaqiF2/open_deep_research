# Open Deep Research 项目整体介绍

## 📋 项目概述

Open Deep Research 是一个基于 LangGraph 构建的开源深度研究代理系统，能够自动进行多步骤的深度研究并生成高质量的研究报告。该系统采用多智能体架构，通过研究监督者（Supervisor）协调多个研究单元（Researcher），实现并行研究、信息整合和报告生成。

### 核心特性

- 🔍 **多源搜索支持**：支持 Tavily、OpenAI、Anthropic 原生网络搜索以及 MCP（Model Context Protocol）工具
- 🤖 **多智能体架构**：采用监督者-研究者模式，支持并行研究执行
- 📊 **智能研究规划**：自动分解研究任务，制定研究策略
- 📝 **高质量报告生成**：自动整合研究结果，生成结构化的研究报告
- ⚙️ **高度可配置**：支持多种 LLM 提供商、搜索 API 和自定义工具
- 🌐 **多语言支持**：支持中英文等多种语言的研究和报告生成

### 项目定位

该项目在 [Deep Research Bench](https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard) 排行榜上取得了优异的成绩（RACE 分数 0.4344，排名第6），证明了其在深度研究任务上的有效性。

---

## 🏗️ 核心代码架构

项目核心代码位于 `src/open_deep_research/` 目录下，包含以下主要模块：

### 1. `configuration.py` - 配置管理模块

**功能**：管理整个系统的配置参数，包括模型选择、搜索 API 配置、研究参数等。

**核心类**：

- **`SearchAPI`**：枚举类型，定义支持的搜索 API 提供商
  - `ANTHROPIC`：Anthropic 原生网络搜索
  - `OPENAI`：OpenAI 原生网络搜索
  - `TAVILY`：Tavily 搜索 API（默认）
  - `NONE`：不使用搜索

- **`MCPConfig`**：MCP 服务器配置
  - `url`：MCP 服务器 URL
  - `tools`：可用的工具列表
  - `auth_required`：是否需要认证

- **`Configuration`**：主配置类，包含以下关键配置项：
  - **通用配置**：
    - `max_structured_output_retries`：结构化输出重试次数（默认 3）
    - `allow_clarification`：是否允许向用户澄清问题（默认 True）
    - `max_concurrent_research_units`：最大并发研究单元数（默认 5）
  
  - **研究配置**：
    - `search_api`：搜索 API 选择
    - `max_researcher_iterations`：研究监督者最大迭代次数（默认 6）
    - `max_react_tool_calls`：单个研究步骤最大工具调用次数（默认 10）
  
  - **模型配置**：
    - `summarization_model`：摘要模型（默认 `openai:gpt-4.1-mini`）
    - `research_model`：研究模型（默认 `openai:gpt-4.1`）
    - `compression_model`：压缩模型（默认 `openai:gpt-4.1`）
    - `final_report_model`：最终报告生成模型（默认 `openai:gpt-4.1`）
    - 每个模型都有对应的 `max_tokens` 配置

**关键方法**：

- `from_runnable_config()`：从 LangGraph 的 RunnableConfig 创建配置实例，支持从环境变量和配置中读取参数

---

### 2. `deep_researcher.py` - 核心研究流程实现

**功能**：实现基于 LangGraph 的完整研究流程，包括用户澄清、研究规划、并行研究执行和报告生成。

**核心工作流**：

#### 2.1 主工作流（`deep_researcher`）

整个研究流程通过 LangGraph 的状态图实现，包含以下节点：

```
START → clarify_with_user → write_research_brief → research_supervisor → final_report_generation → END
```

**节点说明**：

1. **`clarify_with_user`**：用户澄清节点
   - 分析用户输入，判断是否需要澄清问题
   - 如果研究范围不明确，会向用户提问
   - 如果信息充足，直接进入研究阶段
   - 使用 `ClarifyWithUser` 结构化输出

2. **`write_research_brief`**：研究简报生成节点
   - 将用户消息转换为结构化的研究简报
   - 初始化研究监督者的上下文和提示词
   - 使用 `ResearchQuestion` 结构化输出

3. **`research_supervisor`**：研究监督者子图
   - 协调多个研究单元的执行
   - 规划研究策略，分解研究任务
   - 并行执行多个研究任务

4. **`final_report_generation`**：最终报告生成节点
   - 整合所有研究结果
   - 生成结构化的最终研究报告
   - 处理 token 限制错误，支持重试和内容截断

#### 2.2 研究监督者子图（`supervisor_subgraph`）

**节点流程**：

```
START → supervisor → supervisor_tools → supervisor → ... → END
```

**核心函数**：

- **`supervisor()`**：监督者主逻辑
  - 分析研究简报，制定研究策略
  - 使用 `think_tool` 进行战略思考
  - 调用 `ConductResearch` 工具委托研究任务
  - 调用 `ResearchComplete` 工具标记研究完成

- **`supervisor_tools()`**：工具执行处理
  - 处理 `think_tool` 调用（战略反思）
  - 处理 `ConductResearch` 调用（并行执行研究任务）
  - 处理 `ResearchComplete` 调用（结束研究）
  - 限制并发研究单元数量，防止资源耗尽

#### 2.3 研究者子图（`researcher_subgraph`）

**节点流程**：

```
START → researcher → researcher_tools → researcher → ... → compress_research → END
```

**核心函数**：

- **`researcher()`**：研究者主逻辑
  - 接收研究主题，使用可用工具进行深入研究
  - 支持 Tavily 搜索、原生网络搜索、MCP 工具等
  - 使用 `think_tool` 在搜索之间进行反思
  - 支持多轮工具调用循环

- **`researcher_tools()`**：工具执行处理
  - 并行执行所有工具调用（搜索、MCP 工具等）
  - 检测原生网络搜索调用（OpenAI/Anthropic）
  - 检查迭代限制和完成条件
  - 决定继续研究或进入压缩阶段

- **`compress_research()`**：研究结果压缩
  - 将所有研究发现压缩为简洁的结构化摘要
  - 保留所有相关信息，去除冗余
  - 包含源引用和关键摘录
  - 处理 token 限制错误，支持重试

**关键设计特点**：

- **并行执行**：多个研究单元可以同时执行，提高效率
- **错误处理**：完善的 token 限制错误处理，支持自动重试和内容截断
- **状态管理**：使用 LangGraph 的状态图管理复杂的多步骤流程
- **工具集成**：灵活的工具系统，支持多种搜索 API 和 MCP 工具

---

### 3. `prompts.py` - 提示词模板模块

**功能**：定义系统中所有 AI 模型使用的提示词模板，确保研究质量和一致性。

**核心提示词**：

1. **`clarify_with_user_instructions`**：用户澄清提示词
   - 指导模型判断是否需要向用户提问
   - 要求简洁、结构化的问题格式
   - 避免重复提问

2. **`transform_messages_into_research_topic_prompt`**：研究主题转换提示词
   - 将用户消息转换为详细的研究问题
   - 强调具体性、详细性和避免假设
   - 使用第一人称，指导源优先级

3. **`lead_researcher_prompt`**：研究监督者提示词
   - 定义监督者的角色和职责
   - 指导如何分解和委托研究任务
   - 强调使用 `think_tool` 进行战略规划
   - 定义任务委托预算和并发限制

4. **`research_system_prompt`**：研究者系统提示词
   - 定义研究者的角色和任务
   - 指导搜索策略（从广泛到具体）
   - 强调使用 `think_tool` 反思搜索结果
   - 定义工具调用预算和停止条件

5. **`compress_research_system_prompt`**：研究压缩提示词
   - 指导如何清理和整理研究发现
   - 要求保留所有相关信息，去除冗余
   - 定义输出格式（查询列表、发现、源引用）
   - 强调引用规则和源的重要性

6. **`final_report_generation_prompt`**：最终报告生成提示词
   - 指导如何生成结构化的研究报告
   - 支持多种报告结构（比较、列表、概述等）
   - 强调语言一致性（与用户输入语言一致）
   - 定义 Markdown 格式和引用规则

7. **`summarize_webpage_prompt`**：网页摘要提示词
   - 指导如何摘要网页内容
   - 保留关键信息、统计数据、引用等
   - 针对不同类型内容（新闻、科学、产品等）的摘要策略
   - 定义 JSON 输出格式（summary + key_excerpts）

**设计原则**：

- **清晰性**：每个提示词都有明确的任务定义和输出格式
- **一致性**：统一的引用格式和源管理规则
- **灵活性**：支持多种研究场景和报告结构
- **质量保证**：强调信息完整性和准确性

---

### 4. `state.py` - 状态定义模块

**功能**：定义 LangGraph 状态图中使用的所有状态类型和数据结构。

**核心数据结构**：

#### 4.1 结构化输出类

- **`ConductResearch`**：研究委托工具
  - `research_topic`：研究主题（详细描述，至少一段）

- **`ResearchComplete`**：研究完成标记工具
  - 无参数，用于标记研究完成

- **`Summary`**：研究摘要结构
  - `summary`：摘要内容
  - `key_excerpts`：关键摘录

- **`ClarifyWithUser`**：用户澄清结构
  - `need_clarification`：是否需要澄清
  - `question`：澄清问题
  - `verification`：验证消息

- **`ResearchQuestion`**：研究问题结构
  - `research_brief`：研究简报

#### 4.2 状态类

- **`AgentInputState`**：代理输入状态
  - 继承自 `MessagesState`，仅包含 `messages`

- **`AgentState`**：主代理状态
  - `messages`：消息列表
  - `supervisor_messages`：监督者消息列表
  - `research_brief`：研究简报
  - `raw_notes`：原始笔记列表
  - `notes`：笔记列表
  - `final_report`：最终报告

- **`SupervisorState`**：监督者状态
  - `supervisor_messages`：监督者消息列表
  - `research_brief`：研究简报
  - `notes`：笔记列表
  - `research_iterations`：研究迭代次数
  - `raw_notes`：原始笔记列表

- **`ResearcherState`**：研究者状态
  - `researcher_messages`：研究者消息列表
  - `tool_call_iterations`：工具调用迭代次数
  - `research_topic`：研究主题
  - `compressed_research`：压缩后的研究结果
  - `raw_notes`：原始笔记列表

- **`ResearcherOutputState`**：研究者输出状态
  - `compressed_research`：压缩后的研究结果
  - `raw_notes`：原始笔记列表

**状态管理机制**：

- **`override_reducer`**：自定义 reducer 函数，支持状态值的覆盖
- 使用 `Annotated` 类型注解指定 reducer 函数
- 支持消息的追加和覆盖操作

---

### 5. `utils.py` - 工具函数模块

**功能**：提供系统中使用的各种工具函数和辅助功能。

**核心功能模块**：

#### 5.1 Tavily 搜索工具

- **`tavily_search()`**：Tavily 搜索工具函数
  - 执行多个搜索查询
  - 去重搜索结果
  - 并行摘要网页内容
  - 格式化输出结果

- **`tavily_search_async()`**：异步 Tavily 搜索
  - 并行执行多个搜索查询
  - 支持原始内容获取

- **`summarize_webpage()`**：网页摘要函数
  - 使用 AI 模型摘要网页内容
  - 60 秒超时保护
  - 错误处理，返回原始内容作为后备

#### 5.2 反思工具

- **`think_tool()`**：战略反思工具
  - 用于研究过程中的战略规划
  - 记录反思内容，帮助决策

#### 5.3 MCP 工具集成

- **`get_mcp_access_token()`**：获取 MCP 访问令牌
  - 通过 OAuth token 交换获取 MCP 令牌

- **`get_tokens()`**：获取存储的认证令牌
  - 从配置存储中检索令牌
  - 检查令牌过期时间

- **`set_tokens()`**：存储认证令牌
  - 将令牌保存到配置存储

- **`fetch_tokens()`**：获取和刷新 MCP 令牌
  - 尝试获取现有有效令牌
  - 如果过期，获取新令牌

- **`wrap_mcp_authenticate_tool()`**：包装 MCP 工具
  - 添加认证和错误处理
  - 处理 MCP 特定的错误代码

- **`load_mcp_tools()`**：加载 MCP 工具
  - 从 MCP 服务器加载工具
  - 过滤冲突的工具名称
  - 只加载配置中指定的工具

#### 5.4 工具管理

- **`get_search_tool()`**：获取搜索工具
  - 根据配置的搜索 API 返回相应的工具
  - 支持 Anthropic、OpenAI、Tavily 和 None

- **`get_all_tools()`**：获取所有工具
  - 组装完整的工具集
  - 包括研究工具、搜索工具和 MCP 工具
  - 防止工具名称冲突

#### 5.5 原生网络搜索检测

- **`anthropic_websearch_called()`**：检测 Anthropic 原生网络搜索
  - 通过响应元数据检测是否使用了网络搜索

- **`openai_websearch_called()`**：检测 OpenAI 原生网络搜索
  - 通过工具输出检测是否使用了网络搜索

#### 5.6 Token 限制处理

- **`is_token_limit_exceeded()`**：检测 token 限制错误
  - 分析异常，判断是否为 token 限制错误
  - 支持 OpenAI、Anthropic、Gemini 等提供商

- **`get_model_token_limit()`**：获取模型 token 限制
  - 从预定义的模型映射表中查找 token 限制

- **`remove_up_to_last_ai_message()`**：移除消息直到最后一个 AI 消息
  - 用于处理 token 限制错误时的消息截断

#### 5.7 其他工具函数

- **`get_today_str()`**：获取当前日期字符串
  - 格式：`Mon Jan 15, 2024`

- **`get_config_value()`**：获取配置值
  - 处理枚举和 None 值

- **`get_api_key_for_model()`**：获取模型 API 密钥
  - 从环境变量或配置中获取 API 密钥
  - 支持多种模型提供商

- **`get_tavily_api_key()`**：获取 Tavily API 密钥
  - 从环境变量或配置中获取 Tavily API 密钥

- **`get_notes_from_tool_calls()`**：从工具调用中提取笔记
  - 从消息列表中提取工具消息内容

**关键设计特点**：

- **错误处理**：完善的错误处理和超时保护
- **并行执行**：支持异步并行操作，提高性能
- **灵活性**：支持多种搜索 API 和工具集成
- **可扩展性**：易于添加新的工具和功能

---

## 🔄 工作流程详解

### 完整研究流程

1. **用户输入** → 用户提出问题或研究需求

2. **澄清阶段**（可选）
   - 分析用户输入
   - 如果信息不足，向用户提问
   - 如果信息充足，进入研究阶段

3. **研究规划阶段**
   - 将用户消息转换为结构化研究简报
   - 初始化研究监督者

4. **研究执行阶段**（并行）
   - 监督者分析研究简报
   - 使用 `think_tool` 进行战略规划
   - 分解研究任务，调用 `ConductResearch`
   - 多个研究者并行执行研究任务
   - 每个研究者：
     - 使用搜索工具收集信息
     - 使用 `think_tool` 反思搜索结果
     - 多轮工具调用循环
     - 压缩研究结果

5. **结果整合阶段**
   - 监督者收集所有研究结果
   - 评估研究完整性
   - 决定是否需要更多研究或完成研究

6. **报告生成阶段**
   - 整合所有研究发现
   - 生成结构化的最终报告
   - 包含源引用和关键信息

### 并行研究机制

系统支持多个研究单元并行执行，提高研究效率：

- **并发控制**：通过 `max_concurrent_research_units` 配置限制并发数
- **任务分解**：监督者将研究任务分解为独立的子任务
- **结果聚合**：所有研究结果被收集和整合
- **资源管理**：防止资源耗尽和 API 速率限制

---

## 🛠️ 技术栈

- **LangGraph**：工作流编排框架
- **LangChain**：LLM 应用开发框架
- **Pydantic**：数据验证和配置管理
- **Tavily**：搜索 API
- **MCP**：Model Context Protocol，工具集成协议
- **异步编程**：使用 `asyncio` 实现并行操作

---

## 📊 性能特点

- **高效并行**：支持多个研究单元同时执行
- **智能规划**：自动分解和规划研究任务
- **错误恢复**：完善的错误处理和重试机制
- **资源优化**：智能管理 token 使用和 API 调用

---

## 🎯 适用场景

- **学术研究**：深度文献调研和分析
- **市场研究**：产品、竞争对手、行业分析
- **技术调研**：新技术、框架、工具评估
- **新闻分析**：多源信息整合和分析
- **决策支持**：为决策提供全面的信息支持

---

## 📝 总结

Open Deep Research 是一个功能强大、设计精良的深度研究代理系统。通过多智能体架构、并行执行机制和智能规划能力，它能够自动完成复杂的深度研究任务并生成高质量的研究报告。系统的模块化设计和高度可配置性使其能够适应各种研究场景和需求。

核心代码位于 `src/open_deep_research/` 目录下，包含配置管理、工作流实现、提示词模板、状态定义和工具函数等模块，形成了一个完整、可扩展的研究代理系统。

