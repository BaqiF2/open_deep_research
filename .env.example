# 我们只使用Qwen模型来做
OPENAI_API_KEY=
OPENAI_BASE_URL=
#ANTHROPIC_API_KEY=
#GOOGLE_API_KEY=

# 使用TAVILY进行搜索
TAVILY_API_KEY=

# langsminth 监控自行配置
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=
LANGSMITH_TRACING=

# Only necessary for Open Agent Platform
SUPABASE_KEY=
SUPABASE_URL=
# Should be set to true for a production deployment on Open Agent Platform. Should be set to false otherwise, such as for local development.
GET_API_KEYS_FROM_CONFIG=false


# ============================================================================
# Open Deep Research 配置参数
# ============================================================================
#
# 配置优先级：环境变量 > 可配置字典 > 默认值
# 所有配置项都可以通过环境变量设置，格式为：配置名全部大写
# 例如：max_structured_output_retries -> MAX_STRUCTURED_OUTPUT_RETRIES
#
# ============================================================================

# ------------------------------------------------------------------------
# 通用配置
# ------------------------------------------------------------------------

# 模型结构化输出调用的最大重试次数
# 类型：int，默认值：3，范围：1-10
# 用于控制结构化输出失败时的重试次数
MAX_STRUCTURED_OUTPUT_RETRIES=1

# 是否允许研究者在开始研究前向用户询问澄清问题
# 类型：bool，默认值：true
# 启用后，研究者会在开始研究前询问用户澄清问题
ALLOW_CLARIFICATION=true

# 并发运行的研究单元最大数量
# 类型：int，默认值：5，范围：1-20，步长：1
# 控制同时运行的研究子代理数量。注意：并发数越高，可能会遇到速率限制
MAX_CONCURRENT_RESEARCH_UNITS=5

# ------------------------------------------------------------------------
# 研究配置
# ------------------------------------------------------------------------

# 用于研究的搜索 API
# 类型：select，可选值：tavily/openai/anthropic/none
# 可选选项：
#   - tavily: Tavily 搜索 API
#   - openai: OpenAI 原生网页搜索
#   - anthropic: Anthropic 原生网页搜索
#   - none: 不使用搜索 API
# 注意：确保你的研究者模型支持所选的搜索 API
SEARCH_API=tavily

# 研究监督者的最大研究迭代次数
# 类型：int，默认值：6，范围：1-10，步长：1
# 控制研究监督者反思研究并提出后续问题的次数
MAX_RESEARCHER_ITERATIONS=6

# 单个研究者步骤中工具调用迭代的最大次数
# 类型：int，默认值：10，范围：1-30，步长：1
# 控制研究者在单次迭代中可以进行的工具调用次数
MAX_REACT_TOOL_CALLS=10

# ------------------------------------------------------------------------
# 模型配置
# ------------------------------------------------------------------------

# 用于总结 Tavily 搜索结果的研究结果的模型
SUMMARIZATION_MODEL=qwen3-max

# 总结模型的最大输出令牌数
# 类型：int，默认值：8192
SUMMARIZATION_MODEL_MAX_TOKENS=8192

# 总结前网页内容的最大字符长度
# 类型：int，默认值：50000，范围：1000-200000
MAX_CONTENT_LENGTH=50000

# 用于进行研究的模型
# 类型：text，默认值：qwen3-max
# 注意：确保你的研究者模型支持所选的搜索 API
RESEARCH_MODEL=qwen3-max

# 研究模型的最大输出令牌数
# 类型：int，默认值：10000
RESEARCH_MODEL_MAX_TOKENS=10000

# 用于压缩子代理研究发现的模型
# 类型：text，默认值：qwen3-max
# 注意：确保你的压缩模型支持所选的搜索 API
COMPRESSION_MODEL=qwen3-max

# 压缩模型的最大输出令牌数
# 类型：int，默认值：8192
COMPRESSION_MODEL_MAX_TOKENS=8192

# 用于根据所有研究发现撰写最终报告的模型
# 类型：text，默认值：qwen3-max
FINAL_REPORT_MODEL=qwen3-max

# 最终报告模型的最大输出令牌数
# 类型：int，默认值：10000
FINAL_REPORT_MODEL_MAX_TOKENS=10000